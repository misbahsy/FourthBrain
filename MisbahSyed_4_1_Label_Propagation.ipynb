{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MisbahSyed 4.1_Label_Propagation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misbahsy/FourthBrain/blob/main/MisbahSyed_4_1_Label_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieUiNqS3KCZw"
      },
      "source": [
        "# Label Propagation\n",
        "\n",
        "## Label propagation is similar to training a classification model and then using that model to make predictions on test data. The key difference is that in general, our analogue to the test data has no labels against which to evaluate our model. In this exercise, we keep the entire set of true labels for illustrative purposes, but the vast marjority of them play no role in training the model. \n",
        "\n",
        "## This exercise is adapted from scikit-learn's [tutorial](https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_digits.html) on zero shot learning ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IESgGiUAlfZn"
      },
      "source": [
        "### Load the necessary modules and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOVZd8fjgJyK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0An6u8e9loVQ"
      },
      "source": [
        "### Exercise: Load and preprocess the data. \n",
        "1. Shuffle the indices\n",
        "2. Use the shuffled indices to extract 1000 random samples from the features data\n",
        "3. Extract the corresponding 1000 labels and images\n",
        "4. Copy the labels. Treat the first 50 shuffled samples as labeled data and the rest as unlabeled data. Replace the labels after the first 50 with -1.\n",
        "\n",
        "We'll use this copy of our labels (with 50 labels known and the other 950 hidden) to train our model, and use the original copy (with all 1000 labels known) to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyaWhrhCgJyO"
      },
      "source": [
        "# Load the digits dataset\n",
        "# digits = {data,target,indices}; n = 1797\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Set the random state to 2 for reproducibility\n",
        "rng = np.random.RandomState(2)\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Initialize the indices as an ordered array, with each element corresponding to a sample in the dataset\n",
        "indices = np.arange(len(digits.data))\n",
        "\n",
        "# Shuffle the indices\n",
        "rng.shuffle(indices)\n",
        "\n",
        "# Use the shuffled indices to extract 1000 feature vectors, labels, and images\n",
        "n_total_samples = 1000\n",
        "# Features\n",
        "X = digits.data[indices[:n_total_samples]]\n",
        "# Labels\n",
        "y = digits.target[indices[:n_total_samples]]\n",
        "# Images\n",
        "images = digits.images[indices[:n_total_samples]]\n",
        "\n",
        "# Copy the labels\n",
        "y_train = np.copy(y)\n",
        "\n",
        "# Replace all of the elements of y_train after the first 50 with -1, rendering them unlabeled\n",
        "n_labeled_points = 50\n",
        "# Create an ordered array of indices of the training data\n",
        "train_indices = np.arange(n_total_samples)\n",
        "# Define the training data indices after n_labeled_points as unlabeled\n",
        "unlabeled_set = train_indices[n_labeled_points:]\n",
        "# Conduct the label replacement\n",
        "y_train[unlabeled_set] = -1\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb04nCWzeIgh",
        "outputId": "ee4b9896-0a1a-4939-d865-4be9e7e67969"
      },
      "source": [
        "n_total_samples"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "opDBNGH2aZxh",
        "outputId": "4c65d8ba-0f84-40ad-eb1e-f65700ebf24e"
      },
      "source": [
        "digits.DESCR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_hVMtyvomW"
      },
      "source": [
        "### Verify that the labels are randomly distributed and all the labels after the first 50 in `y_train` are hidden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39CAoaBzgJyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6a1e9c-61f0-4b6a-8354-1dccd9e90f2a"
      },
      "source": [
        "print(y_train[0:100])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4  0  9  1  4  7  1  5  1  6  6  7  6  1  5  5  4  6  2  7  4  6  4  1\n",
            "  5  2  9  5  4  6  5  6  3  4  0  9  9  8  4  6  8  8  5  7  9  6  9  6\n",
            "  1  3 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40hk3UKewEZe"
      },
      "source": [
        "### Exercise: Train the label propagation model with `gamma = 0.25` and `max_iter = 20`\n",
        "\n",
        "### Make sure you pass in the correct version of the target array, i.e. the one containing unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wHcs3qkgJyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc8a0b5-0160-4139-96a0-52b413649b69"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Initialize the model\n",
        "lp_model = LabelSpreading(gamma=0.25, max_iter=20)\n",
        "# Train the model\n",
        "lp_model.fit(X, y_train)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelSpreading(alpha=0.2, gamma=0.25, kernel='rbf', max_iter=20, n_jobs=None,\n",
              "               n_neighbors=7, tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTBwLj2Gy8qM"
      },
      "source": [
        "### Exercise: Evaluate the model's performance on the unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O3_LqbQfwAv",
        "outputId": "0f98d947-95f5-4642-9ca0-91a46bfacb93"
      },
      "source": [
        "lp_model.transduction_[unlabeled_set].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(950,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFO-PxjgJya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495608da-53f0-475f-b997-60ae8cb94d71"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Extract the label predictions for the unlabeled data\n",
        "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
        "# Extract the true labels of the unlabeled data\n",
        "true_labels = y[unlabeled_set]\n",
        "# Compute the confusion matrix between the true and predicted labels of the unlabeled data\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
        "### END CODE HERE ###\n",
        "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
        "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "print(\"Confusion matrix\")\n",
        "print(cm)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Spreading model: 50 labeled & 950 unlabeled points (1000 total)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        98\n",
            "           1       0.85      0.90      0.88        93\n",
            "           2       0.99      0.78      0.87        91\n",
            "           3       0.92      0.90      0.91       108\n",
            "           4       0.97      1.00      0.98        88\n",
            "           5       0.97      0.93      0.95       102\n",
            "           6       0.97      1.00      0.99       100\n",
            "           7       0.98      0.91      0.94        91\n",
            "           8       0.86      0.82      0.84        87\n",
            "           9       0.77      0.97      0.86        92\n",
            "\n",
            "    accuracy                           0.92       950\n",
            "   macro avg       0.93      0.92      0.92       950\n",
            "weighted avg       0.93      0.92      0.92       950\n",
            "\n",
            "Confusion matrix\n",
            "[[ 98   0   0   0   0   0   0   0   0   0]\n",
            " [  0  84   0   0   1   1   0   0   3   4]\n",
            " [  0  12  71   0   0   0   0   1   7   0]\n",
            " [  0   0   0  97   0   0   0   1   0  10]\n",
            " [  0   0   0   0  88   0   0   0   0   0]\n",
            " [  0   0   0   0   0  95   0   0   0   7]\n",
            " [  0   0   0   0   0   0 100   0   0   0]\n",
            " [  0   0   0   0   0   2   0  83   0   6]\n",
            " [  0   3   1   8   1   0   3   0  71   0]\n",
            " [  0   0   0   0   1   0   0   0   2  89]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwlk3ptY1YrL"
      },
      "source": [
        "### Exercise: Find the 10 most uncertain labels in descending order of uncertainty, i.e. the labels for which the model made the least confident predictions. Plot the associated images. Observe any discrepancies between predicted and true labels. Do you see any patterns? What might account for them? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ajvW97mgJyf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "e6ff6378-4f92-4b67-8eca-15b6029d61ed"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Calculate uncertainty values for each transduced distribution\n",
        "# You may scipy stats' entropy() function useful.\n",
        "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
        "\n",
        "# Pick the top 10 most uncertain labels, in descending order of uncertainty\n",
        "uncertainty_index = np.argsort(pred_entropies)[-10:]\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "# Plot\n",
        "f = plt.figure(figsize=(7, 5))\n",
        "for index, image_index in enumerate(uncertainty_index):\n",
        "    image = images[image_index]\n",
        "\n",
        "    sub = f.add_subplot(2, 5, index + 1)\n",
        "    sub.imshow(image, cmap=plt.cm.gray_r)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    sub.set_title('predict: %i\\ntrue: %i' % (\n",
        "        lp_model.transduction_[image_index], y[image_index]))\n",
        "\n",
        "f.suptitle('Learning with small amount of labeled data')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD119mlU69jb"
      },
      "source": [
        "### Exercise: Repeat the experiment with 10, 100, and 250 labeled images. How do the differing numbers of labeled samples affect the model's performance? Which number detections yield the most errors?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmHbAwxBiXFc"
      },
      "source": [
        "# With 100 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypt99rc5hXAr"
      },
      "source": [
        "# Load the digits dataset\n",
        "# digits = {data,target,indices}; n = 1797\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Set the random state to 2 for reproducibility\n",
        "rng = np.random.RandomState(2)\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Initialize the indices as an ordered array, with each element corresponding to a sample in the dataset\n",
        "indices = np.arange(len(digits.data))\n",
        "\n",
        "# Shuffle the indices\n",
        "rng.shuffle(indices)\n",
        "\n",
        "# Use the shuffled indices to extract 1000 feature vectors, labels, and images\n",
        "n_total_samples = 1000\n",
        "# Features\n",
        "X = digits.data[indices[:n_total_samples]]\n",
        "# Labels\n",
        "y = digits.target[indices[:n_total_samples]]\n",
        "# Images\n",
        "images = digits.images[indices[:n_total_samples]]\n",
        "\n",
        "# Copy the labels\n",
        "y_train = np.copy(y)\n",
        "\n",
        "# Replace all of the elements of y_train after the first 50 with -1, rendering them unlabeled\n",
        "n_labeled_points = 100\n",
        "# Create an ordered array of indices of the training data\n",
        "train_indices = np.arange(n_total_samples)\n",
        "# Define the training data indices after n_labeled_points as unlabeled\n",
        "unlabeled_set = train_indices[n_labeled_points:]\n",
        "# Conduct the label replacement\n",
        "y_train[unlabeled_set] = -1\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLTwM53lhbt7",
        "outputId": "45ae7fda-504a-4191-e678-c4f47639ac1b"
      },
      "source": [
        "print(y_train[0:1000])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4  0  9  1  4  7  1  5  1  6  6  7  6  1  5  5  4  6  2  7  4  6  4  1\n",
            "  5  2  9  5  4  6  5  6  3  4  0  9  9  8  4  6  8  8  5  7  9  6  9  6\n",
            "  1  3  0  1  9  7  3  3  1  1  8  8  9  8  5  4  4  7  3  5  8  4  3  1\n",
            "  3  8  7  3  3  0  8  7  2  8  5  3  8  7  6  4  6  2  2  0  1  1  5  3\n",
            "  5  7  6  8 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-OYhbTBhhKz",
        "outputId": "fc52e41a-ebf2-4de8-8f5e-bf8666ae8ed1"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Initialize the model\n",
        "lp_model = LabelSpreading(gamma=0.25, max_iter=20)\n",
        "# Train the model\n",
        "lp_model.fit(X, y_train)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelSpreading(alpha=0.2, gamma=0.25, kernel='rbf', max_iter=20, n_jobs=None,\n",
              "               n_neighbors=7, tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcYSrIiphmrT",
        "outputId": "2488621b-22ae-4d37-87a0-36132b5fb843"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Extract the label predictions for the unlabeled data\n",
        "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
        "# Extract the true labels of the unlabeled data\n",
        "true_labels = y[unlabeled_set]\n",
        "# Compute the confusion matrix between the true and predicted labels of the unlabeled data\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
        "### END CODE HERE ###\n",
        "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
        "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "print(\"Confusion matrix\")\n",
        "print(cm)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Spreading model: 100 labeled & 900 unlabeled points (1000 total)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        95\n",
            "           1       0.92      0.99      0.96        87\n",
            "           2       1.00      0.90      0.95        88\n",
            "           3       0.93      0.96      0.95        99\n",
            "           4       0.98      1.00      0.99        84\n",
            "           5       0.97      0.93      0.95        97\n",
            "           6       1.00      1.00      1.00        97\n",
            "           7       1.00      0.91      0.95        85\n",
            "           8       0.96      0.92      0.94        78\n",
            "           9       0.83      0.96      0.89        90\n",
            "\n",
            "    accuracy                           0.96       900\n",
            "   macro avg       0.96      0.96      0.96       900\n",
            "weighted avg       0.96      0.96      0.96       900\n",
            "\n",
            "Confusion matrix\n",
            "[[95  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 86  0  0  0  1  0  0  0  0]\n",
            " [ 0  4 79  3  0  0  0  0  2  0]\n",
            " [ 0  0  0 95  0  0  0  0  0  4]\n",
            " [ 0  0  0  0 84  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 90  0  0  0  7]\n",
            " [ 0  0  0  0  0  0 97  0  0  0]\n",
            " [ 0  0  0  0  0  2  0 77  0  6]\n",
            " [ 0  3  0  2  1  0  0  0 72  0]\n",
            " [ 0  0  0  2  1  0  0  0  1 86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "4p18njTmhsr8",
        "outputId": "ae115a36-a10f-41b3-9343-9e35f9f426d2"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Calculate uncertainty values for each transduced distribution\n",
        "# You may scipy stats' entropy() function useful.\n",
        "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
        "\n",
        "# Pick the top 10 most uncertain labels, in descending order of uncertainty\n",
        "uncertainty_index = np.argsort(pred_entropies)[-10:]\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "# Plot\n",
        "f = plt.figure(figsize=(7, 5))\n",
        "for index, image_index in enumerate(uncertainty_index):\n",
        "    image = images[image_index]\n",
        "\n",
        "    sub = f.add_subplot(2, 5, index + 1)\n",
        "    sub.imshow(image, cmap=plt.cm.gray_r)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    sub.set_title('predict: %i\\ntrue: %i' % (\n",
        "        lp_model.transduction_[image_index], y[image_index]))\n",
        "\n",
        "f.suptitle('Learning with small amount of labeled data')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4xMwiSBiQow"
      },
      "source": [
        "# With 250 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DsIykSiOqP"
      },
      "source": [
        "# Load the digits dataset\n",
        "# digits = {data,target,indices}; n = 1797\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Set the random state to 2 for reproducibility\n",
        "rng = np.random.RandomState(2)\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Initialize the indices as an ordered array, with each element corresponding to a sample in the dataset\n",
        "indices = np.arange(len(digits.data))\n",
        "\n",
        "# Shuffle the indices\n",
        "rng.shuffle(indices)\n",
        "\n",
        "# Use the shuffled indices to extract 1000 feature vectors, labels, and images\n",
        "n_total_samples = 1000\n",
        "# Features\n",
        "X = digits.data[indices[:n_total_samples]]\n",
        "# Labels\n",
        "y = digits.target[indices[:n_total_samples]]\n",
        "# Images\n",
        "images = digits.images[indices[:n_total_samples]]\n",
        "\n",
        "# Copy the labels\n",
        "y_train = np.copy(y)\n",
        "\n",
        "# Replace all of the elements of y_train after the first 50 with -1, rendering them unlabeled\n",
        "n_labeled_points = 250\n",
        "# Create an ordered array of indices of the training data\n",
        "train_indices = np.arange(n_total_samples)\n",
        "# Define the training data indices after n_labeled_points as unlabeled\n",
        "unlabeled_set = train_indices[n_labeled_points:]\n",
        "# Conduct the label replacement\n",
        "y_train[unlabeled_set] = -1\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqUJPLAiOqQ",
        "outputId": "2bf8c1d3-0b7e-4282-99b2-c325b20b44c0"
      },
      "source": [
        "print(y_train[0:1000])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4  0  9  1  4  7  1  5  1  6  6  7  6  1  5  5  4  6  2  7  4  6  4  1\n",
            "  5  2  9  5  4  6  5  6  3  4  0  9  9  8  4  6  8  8  5  7  9  6  9  6\n",
            "  1  3  0  1  9  7  3  3  1  1  8  8  9  8  5  4  4  7  3  5  8  4  3  1\n",
            "  3  8  7  3  3  0  8  7  2  8  5  3  8  7  6  4  6  2  2  0  1  1  5  3\n",
            "  5  7  6  8  2  2  6  4  6  7  3  7  3  9  4  7  0  3  5  8  5  0  3  9\n",
            "  2  7  3  2  0  8  1  9  2  1  9  1  0  3  4  3  0  9  3  2  2  7  3  1\n",
            "  6  7  2  8  3  1  1  6  4  8  2  1  8  4  1  3  1  1  9  5  4  8  7  4\n",
            "  8  9  5  7  6  9  0  0  4  0  0  4  0  6  5  8  8  3  7  9  2  0  3  2\n",
            "  7  3  0  2  1  5  2  7  0  6  9  3  1  1  3  5  2  3  5  2  1  2  9  4\n",
            "  6  5  5  5  9  7  1  5  9  6  3  7  1  7  5  1  7  2  7  5  5  4  8  6\n",
            "  6  2  8  7  3  7  8  0  9  5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVSOo_CCiOqQ",
        "outputId": "11292b2b-f3b2-4967-964b-5cbc5b8b62d1"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Initialize the model\n",
        "lp_model = LabelSpreading(gamma=0.25, max_iter=20)\n",
        "# Train the model\n",
        "lp_model.fit(X, y_train)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelSpreading(alpha=0.2, gamma=0.25, kernel='rbf', max_iter=20, n_jobs=None,\n",
              "               n_neighbors=7, tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfg9bgfViOqQ",
        "outputId": "c1a68431-4a3c-43b5-d58b-07710a7c4724"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Extract the label predictions for the unlabeled data\n",
        "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
        "# Extract the true labels of the unlabeled data\n",
        "true_labels = y[unlabeled_set]\n",
        "# Compute the confusion matrix between the true and predicted labels of the unlabeled data\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
        "### END CODE HERE ###\n",
        "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
        "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "print(\"Confusion matrix\")\n",
        "print(cm)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Spreading model: 250 labeled & 750 unlabeled points (1000 total)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        81\n",
            "           1       0.93      0.97      0.95        70\n",
            "           2       1.00      0.90      0.95        70\n",
            "           3       0.91      0.99      0.95        80\n",
            "           4       1.00      1.00      1.00        73\n",
            "           5       0.99      0.93      0.96        81\n",
            "           6       1.00      1.00      1.00        86\n",
            "           7       1.00      0.99      0.99        67\n",
            "           8       0.94      0.89      0.91        66\n",
            "           9       0.89      0.96      0.92        76\n",
            "\n",
            "    accuracy                           0.96       750\n",
            "   macro avg       0.97      0.96      0.96       750\n",
            "weighted avg       0.97      0.96      0.96       750\n",
            "\n",
            "Confusion matrix\n",
            "[[81  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 68  0  0  0  1  0  0  1  0]\n",
            " [ 0  4 63  1  0  0  0  0  2  0]\n",
            " [ 0  0  0 79  0  0  0  0  0  1]\n",
            " [ 0  0  0  0 73  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 75  0  0  0  6]\n",
            " [ 0  0  0  0  0  0 86  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 66  0  1]\n",
            " [ 0  1  0  5  0  0  0  0 59  1]\n",
            " [ 0  0  0  2  0  0  0  0  1 73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og5amIeXiOqR"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "GPihyhYWiOqR",
        "outputId": "6870d1b9-f3b3-47c0-f9fc-4782eb7fbbe3"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Calculate uncertainty values for each transduced distribution\n",
        "# You may scipy stats' entropy() function useful.\n",
        "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
        "\n",
        "# Pick the top 10 most uncertain labels, in descending order of uncertainty\n",
        "uncertainty_index = np.argsort(pred_entropies)[-10:]\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "# Plot\n",
        "f = plt.figure(figsize=(7, 5))\n",
        "for index, image_index in enumerate(uncertainty_index):\n",
        "    image = images[image_index]\n",
        "\n",
        "    sub = f.add_subplot(2, 5, index + 1)\n",
        "    sub.imshow(image, cmap=plt.cm.gray_r)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    sub.set_title('predict: %i\\ntrue: %i' % (\n",
        "        lp_model.transduction_[image_index], y[image_index]))\n",
        "\n",
        "f.suptitle('Learning with small amount of labeled data')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6HB8RzhixqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}